{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X-cp_kAxCAY2"
   },
   "source": [
    "# Amazon Fine Food Reviews Analysis\n",
    "\n",
    "\n",
    "Data Source: https://www.kaggle.com/snap/amazon-fine-food-reviews <br>\n",
    "\n",
    "EDA: https://nycdatascience.com/blog/student-works/amazon-fine-foods-visualization/\n",
    "\n",
    "\n",
    "The Amazon Fine Food Reviews dataset consists of reviews of fine foods from Amazon.<br>\n",
    "\n",
    "Number of reviews: 568,454<br>\n",
    "Number of users: 256,059<br>\n",
    "Number of products: 74,258<br>\n",
    "Timespan: Oct 1999 - Oct 2012<br>\n",
    "Number of Attributes/Columns in data: 10 \n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "1. Id\n",
    "2. ProductId - unique identifier for the product\n",
    "3. UserId - unqiue identifier for the user\n",
    "4. ProfileName\n",
    "5. HelpfulnessNumerator - number of users who found the review helpful\n",
    "6. HelpfulnessDenominator - number of users who indicated whether they found the review helpful or not\n",
    "7. Score - rating between 1 and 5\n",
    "8. Time - timestamp for the review\n",
    "9. Summary - brief summary of the review\n",
    "10. Text - text of the review\n",
    "\n",
    "\n",
    "#### Objective:\n",
    "Given a review, determine whether the review is positive (Rating of 4 or 5) or negative (rating of 1 or 2).\n",
    "\n",
    "<br>\n",
    "[Q] How to determine if a review is positive or negative?<br>\n",
    "<br> \n",
    "[Ans] We could use the Score/Rating. A rating of 4 or 5 could be cosnidered a positive review. A review of 1 or 2 could be considered negative. A review of 3 is nuetral and ignored. This is an approximate and proxy way of determining the polarity (positivity/negativity) of a review.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WHC_UQTuCAY4"
   },
   "source": [
    "## Loading the data\n",
    "\n",
    "The dataset is available in two forms\n",
    "1. .csv file\n",
    "2. SQLite Database\n",
    "\n",
    "In order to load the data, We have used the SQLITE dataset as it easier to query the data and visualise the data efficiently.\n",
    "<br> \n",
    "\n",
    "Here as we only want to get the global sentiment of the recommendations (positive or negative), we will purposefully ignore all Scores equal to 3. If the score id above 3, then the recommendation wil be set to \"positive\". Otherwise, it will be set to \"negative\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Collecting ipython-sql',\n",
       " '  Downloading https://files.pythonhosted.org/packages/ab/df/427e7cf05ffc67e78672ad57dce2436c1e825129033effe6fcaf804d0c60/ipython_sql-0.3.9-py2.py3-none-any.whl',\n",
       " 'Requirement already satisfied: sqlalchemy>=0.6.7 in c:\\\\users\\\\asus\\\\anaconda3\\\\lib\\\\site-packages (from ipython-sql) (1.3.1)',\n",
       " 'Collecting sqlparse (from ipython-sql)',\n",
       " '  Downloading https://files.pythonhosted.org/packages/ef/53/900f7d2a54557c6a37886585a91336520e5539e3ae2423ff1102daf4f3a7/sqlparse-0.3.0-py2.py3-none-any.whl',\n",
       " 'Requirement already satisfied: ipython>=1.0 in c:\\\\users\\\\asus\\\\anaconda3\\\\lib\\\\site-packages (from ipython-sql) (7.4.0)',\n",
       " 'Collecting prettytable (from ipython-sql)',\n",
       " '  Downloading https://files.pythonhosted.org/packages/ef/30/4b0746848746ed5941f052479e7c23d2b56d174b82f4fd34a25e389831f5/prettytable-0.7.2.tar.bz2',\n",
       " 'Requirement already satisfied: ipython-genutils>=0.1.0 in c:\\\\users\\\\asus\\\\anaconda3\\\\lib\\\\site-packages (from ipython-sql) (0.2.0)',\n",
       " 'Requirement already satisfied: six in c:\\\\users\\\\asus\\\\anaconda3\\\\lib\\\\site-packages (from ipython-sql) (1.12.0)',\n",
       " 'Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\\\users\\\\asus\\\\anaconda3\\\\lib\\\\site-packages (from ipython>=1.0->ipython-sql) (0.4.1)',\n",
       " 'Requirement already satisfied: jedi>=0.10 in c:\\\\users\\\\asus\\\\anaconda3\\\\lib\\\\site-packages (from ipython>=1.0->ipython-sql) (0.13.3)',\n",
       " 'Requirement already satisfied: decorator in c:\\\\users\\\\asus\\\\anaconda3\\\\lib\\\\site-packages (from ipython>=1.0->ipython-sql) (4.4.0)',\n",
       " 'Requirement already satisfied: pickleshare in c:\\\\users\\\\asus\\\\anaconda3\\\\lib\\\\site-packages (from ipython>=1.0->ipython-sql) (0.7.5)',\n",
       " 'Requirement already satisfied: setuptools>=18.5 in c:\\\\users\\\\asus\\\\anaconda3\\\\lib\\\\site-packages (from ipython>=1.0->ipython-sql) (40.8.0)',\n",
       " 'Requirement already satisfied: pygments in c:\\\\users\\\\asus\\\\anaconda3\\\\lib\\\\site-packages (from ipython>=1.0->ipython-sql) (2.3.1)',\n",
       " 'Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in c:\\\\users\\\\asus\\\\anaconda3\\\\lib\\\\site-packages (from ipython>=1.0->ipython-sql) (2.0.9)',\n",
       " 'Requirement already satisfied: backcall in c:\\\\users\\\\asus\\\\anaconda3\\\\lib\\\\site-packages (from ipython>=1.0->ipython-sql) (0.1.0)',\n",
       " 'Requirement already satisfied: traitlets>=4.2 in c:\\\\users\\\\asus\\\\anaconda3\\\\lib\\\\site-packages (from ipython>=1.0->ipython-sql) (4.3.2)',\n",
       " 'Requirement already satisfied: parso>=0.3.0 in c:\\\\users\\\\asus\\\\anaconda3\\\\lib\\\\site-packages (from jedi>=0.10->ipython>=1.0->ipython-sql) (0.3.4)',\n",
       " 'Requirement already satisfied: wcwidth in c:\\\\users\\\\asus\\\\anaconda3\\\\lib\\\\site-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=1.0->ipython-sql) (0.1.7)',\n",
       " 'Building wheels for collected packages: prettytable',\n",
       " '  Building wheel for prettytable (setup.py): started',\n",
       " \"  Building wheel for prettytable (setup.py): finished with status 'done'\",\n",
       " '  Stored in directory: C:\\\\Users\\\\Asus\\\\AppData\\\\Local\\\\pip\\\\Cache\\\\wheels\\\\80\\\\34\\\\1c\\\\3967380d9676d162cb59513bd9dc862d0584e045a162095606',\n",
       " 'Successfully built prettytable',\n",
       " 'Installing collected packages: sqlparse, prettytable, ipython-sql',\n",
       " 'Successfully installed ipython-sql-0.3.9 prettytable-0.7.2 sqlparse-0.3.0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%!\n",
    "pip install --trusted-host pypi.org ipython-sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Connected: @None'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql sqlite://33\n",
    "    *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite://\n",
      "Done.\n",
      "1 rows affected.\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>ID</th>\n",
       "        <th>Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1</td>\n",
       "        <td>A</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(1, 'A')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "create table pslv(ID int, Name varchar(10));\n",
    "insert into pslv values(1, 'A');\n",
    "select * from pslv;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite://\n",
      "(sqlite3.OperationalError) near \"show\": syntax error\n",
      "[SQL: show tables]\n",
      "(Background on this error at: http://sqlalche.me/e/e3q8)\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "show tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PvDdRsHgCAY5",
    "outputId": "65b237f2-2ead-4721-f95a-15ed0bb06d04"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk             \n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import re\n",
    "# Tutorial about Python regular expressions: https://pymotw.com/2/re/\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "#from gensim.models import Word2Vec\n",
    "#from gensim.models import KeyedVectors\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QOI7X2YgCAY_"
   },
   "source": [
    "# [1]. Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3iYH2p1ECAZA",
    "outputId": "3feca330-8e21-4173-ad7c-88eb4d81668e"
   },
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "unable to open database file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-ce88661bd33a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# using the SQLite Table to read data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msqlite3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/Users/nilesh/Downloads/Data Science/Test_Dataset/amazon-fine-food-reviews/database.sqlite'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#filtering only positive and negative reviews i.e.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# not taking into consideration those reviews with Score=3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperationalError\u001b[0m: unable to open database file"
     ]
    }
   ],
   "source": [
    "\n",
    "# using the SQLite Table to read data.\n",
    "con = sqlite3.connect('/Users/nilesh/Downloads/Data Science/Test_Dataset/amazon-fine-food-reviews/database.sqlite') \n",
    "#filtering only positive and negative reviews i.e. \n",
    "# not taking into consideration those reviews with Score=3\n",
    "# SELECT * FROM Reviews WHERE Score != 3 LIMIT 500000, will give top 500000 data points\n",
    "# you can change the number to any other number based on your computing power\n",
    "\n",
    "# filtered_data = pd.read_sql_query(\"\"\" SELECT * FROM Reviews WHERE Score != 3 LIMIT 500000\"\"\", con) \n",
    "# for tsne assignment you can take 5k data points\n",
    "\n",
    "filtered_data = pd.read_sql_query(\"\"\" SELECT * FROM Reviews where score != 3\"\"\", con) \n",
    "'''\n",
    "# Give reviews with Score>3 a positive rating, and reviews with a score<3 a negative rating.\n",
    "def partition(x):\n",
    "    if x < 3:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "#changing reviews with score less than 3 to be positive and vice-versa\n",
    "actualScore = filtered_data['Score']\n",
    "positiveNegative = actualScore.map(partition) \n",
    "filtered_data['Score'] = positiveNegative\n",
    "print(\"Number of data points in our data\", filtered_data.shape)\n",
    "'''\n",
    "print(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I1jf03kECAZF"
   },
   "outputs": [],
   "source": [
    "display = pd.read_sql_query(\"\"\"\n",
    "SELECT UserId, ProductId, ProfileName, Time, Score, Text, COUNT(*)\n",
    "FROM Reviews\n",
    "GROUP BY UserId\n",
    "HAVING COUNT(*)>1\n",
    "\"\"\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ja8xSefOCAZH",
    "outputId": "2cbd0705-618b-47cf-ce18-f3d0d4063cbf"
   },
   "outputs": [],
   "source": [
    "print(display.shape)\n",
    "display.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u5ctUTW-CAZK",
    "outputId": "41439570-0ff9-44bb-9c05-e87bcb3dd6b7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>Time</th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "      <th>COUNT(*)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80638</th>\n",
       "      <td>AZY10LLTJ71NX</td>\n",
       "      <td>B001ATMQK2</td>\n",
       "      <td>undertheshrine \"undertheshrine\"</td>\n",
       "      <td>1296691200</td>\n",
       "      <td>5</td>\n",
       "      <td>I bought this 6 pack because for the price tha...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              UserId   ProductId                      ProfileName        Time  \\\n",
       "80638  AZY10LLTJ71NX  B001ATMQK2  undertheshrine \"undertheshrine\"  1296691200   \n",
       "\n",
       "       Score                                               Text  COUNT(*)  \n",
       "80638      5  I bought this 6 pack because for the price tha...         5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display[display['UserId']=='AZY10LLTJ71NX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tiaXnkZxCAZO",
    "outputId": "0bbd60e6-e66b-4f20-9060-bf0cfe143b1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393063"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display['COUNT(*)'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TX5b3dc5CAZS"
   },
   "source": [
    "#  Exploratory Data Analysis\n",
    "\n",
    "## [2] Data Cleaning: Deduplication\n",
    "\n",
    "It is observed (as shown in the table below) that the reviews data had many duplicate entries. Hence it was necessary to remove duplicates in order to get unbiased results for the analysis of the data.  Following is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4jW_0WxCCAZT",
    "outputId": "4e526ab2-98f3-46ae-93dc-3e061cb06d59",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78445</td>\n",
       "      <td>B000HDL1RQ</td>\n",
       "      <td>AR5J8UI46CURR</td>\n",
       "      <td>Geetha Krishnan</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1199577600</td>\n",
       "      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n",
       "      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>138317</td>\n",
       "      <td>B000HDOPYC</td>\n",
       "      <td>AR5J8UI46CURR</td>\n",
       "      <td>Geetha Krishnan</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1199577600</td>\n",
       "      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n",
       "      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>138277</td>\n",
       "      <td>B000HDOPYM</td>\n",
       "      <td>AR5J8UI46CURR</td>\n",
       "      <td>Geetha Krishnan</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1199577600</td>\n",
       "      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n",
       "      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id   ProductId         UserId      ProfileName  HelpfulnessNumerator  \\\n",
       "0   78445  B000HDL1RQ  AR5J8UI46CURR  Geetha Krishnan                     2   \n",
       "1  138317  B000HDOPYC  AR5J8UI46CURR  Geetha Krishnan                     2   \n",
       "2  138277  B000HDOPYM  AR5J8UI46CURR  Geetha Krishnan                     2   \n",
       "\n",
       "   HelpfulnessDenominator  Score        Time  \\\n",
       "0                       2      5  1199577600   \n",
       "1                       2      5  1199577600   \n",
       "2                       2      5  1199577600   \n",
       "\n",
       "                             Summary  \\\n",
       "0  LOACKER QUADRATINI VANILLA WAFERS   \n",
       "1  LOACKER QUADRATINI VANILLA WAFERS   \n",
       "2  LOACKER QUADRATINI VANILLA WAFERS   \n",
       "\n",
       "                                                Text  \n",
       "0  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...  \n",
       "1  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...  \n",
       "2  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "display= pd.read_sql_query(\"\"\"SELECT * FROM Reviews \n",
    "where score != 3 and UserId=\"AR5J8UI46CURR\" ORDER BY ProductID\n",
    "\"\"\", con)\n",
    "#print(display)\n",
    "display.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BzVTlHiMCAZV"
   },
   "source": [
    "As can be seen above the same user has multiple reviews of the with the same values for HelpfulnessNumerator, HelpfulnessDenominator, Score, Time, Summary and Text  and on doing analysis it was found that <br>\n",
    "<br> \n",
    "ProductId=B000HDOPZG was Loacker Quadratini Vanilla Wafer Cookies, 8.82-Ounce Packages (Pack of 8)<br>\n",
    "<br> \n",
    "ProductId=B000HDL1RQ was Loacker Quadratini Lemon Wafer Cookies, 8.82-Ounce Packages (Pack of 8) and so on<br>\n",
    "\n",
    "It was inferred after analysis that reviews with same parameters other than ProductId belonged to the same product just having different flavour or quantity. Hence in order to reduce redundancy it was decided to eliminate the rows having same parameters.<br>\n",
    "\n",
    "The method used for the same was that we first sort the data according to ProductId and then just keep the first similar product review and delelte the others. for eg. in the above just the review for ProductId=B000HDL1RQ remains. This method ensures that there is only one representative for each product and deduplication without sorting would lead to possibility of different representatives still existing for the same product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DGy2NM7BCAZX"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138706</th>\n",
       "      <td>150524</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>ACITT7DI6IDDL</td>\n",
       "      <td>shari zychinski</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>939340800</td>\n",
       "      <td>EVERY book is educational</td>\n",
       "      <td>this witty little book makes my son laugh at l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138688</th>\n",
       "      <td>150506</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A2IW4PEEKO2R0U</td>\n",
       "      <td>Tracy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1194739200</td>\n",
       "      <td>Love the book, miss the hard cover version</td>\n",
       "      <td>I grew up reading these Sendak books, and watc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138689</th>\n",
       "      <td>150507</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A1S4A3IQ2MU7V4</td>\n",
       "      <td>sally sue \"sally sue\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1191456000</td>\n",
       "      <td>chicken soup with rice months</td>\n",
       "      <td>This is a fun way for children to learn their ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138690</th>\n",
       "      <td>150508</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>AZGXZ2UUK6X</td>\n",
       "      <td>Catherine Hallberg \"(Kate)\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1076025600</td>\n",
       "      <td>a good swingy rhythm for reading aloud</td>\n",
       "      <td>This is a great little book to read aloud- it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138691</th>\n",
       "      <td>150509</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A3CMRKGE0P909G</td>\n",
       "      <td>Teresa</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1018396800</td>\n",
       "      <td>A great way to learn the months</td>\n",
       "      <td>This is a book of poetry about the months of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138693</th>\n",
       "      <td>150511</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A1C9K534BCI9GO</td>\n",
       "      <td>Laura Purdie Salas</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1344211200</td>\n",
       "      <td>Charming and childlike</td>\n",
       "      <td>A charming, rhyming book that describes the ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138694</th>\n",
       "      <td>150512</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A1DJXZA5V5FFVA</td>\n",
       "      <td>A. Conway</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1338249600</td>\n",
       "      <td>Must have.</td>\n",
       "      <td>I set aside at least an hour each day to read ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138695</th>\n",
       "      <td>150513</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>ASH0DZQQF6AIZ</td>\n",
       "      <td>tessarat</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1325721600</td>\n",
       "      <td>A classic</td>\n",
       "      <td>I remembered this book from my childhood and g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138696</th>\n",
       "      <td>150514</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A2ONB6ZA292PA</td>\n",
       "      <td>Rosalind Matzner</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1313884800</td>\n",
       "      <td>Chicken soup with Rice</td>\n",
       "      <td>It's a great book with adorable illustrations....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138697</th>\n",
       "      <td>150515</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A2RTT81R6Y3R7X</td>\n",
       "      <td>Lindylu</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1303171200</td>\n",
       "      <td>One of our family's favorite books</td>\n",
       "      <td>This book is a family favorite and was read to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138687</th>\n",
       "      <td>150505</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A2PTSM496CF40Z</td>\n",
       "      <td>Jason A. Teeple \"Nobody made a greater mistak...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1210809600</td>\n",
       "      <td>A classic</td>\n",
       "      <td>Get the movie or sound track and sing along wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138698</th>\n",
       "      <td>150516</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A3OI7ZGH6WZJ5G</td>\n",
       "      <td>Mary Jane Rogers \"Maedchen\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1293840000</td>\n",
       "      <td>Darling!</td>\n",
       "      <td>The same author wrote \"Where the Wild Things A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138700</th>\n",
       "      <td>150518</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>AK1L4EJBA23JF</td>\n",
       "      <td>L. M. Kraus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1288224000</td>\n",
       "      <td>love this book</td>\n",
       "      <td>Great book, perfect condition arrived in a sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138701</th>\n",
       "      <td>150519</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A12HY5OZ2QNK4N</td>\n",
       "      <td>Elizabeth H. Roessner</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1256774400</td>\n",
       "      <td>It's a great book!</td>\n",
       "      <td>I've always loved chicken soup and rice. My la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138702</th>\n",
       "      <td>150520</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>ADBFSA9KTQANE</td>\n",
       "      <td>James L. Hammock \"Pucks Buddy\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1256688000</td>\n",
       "      <td>Great Gift</td>\n",
       "      <td>This book was purchased as a birthday gift for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138703</th>\n",
       "      <td>150521</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A3RMCRB2NDTDYP</td>\n",
       "      <td>Carol Carruthers</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1243468800</td>\n",
       "      <td>This book is great!</td>\n",
       "      <td>My 7 year old daughter brought this book home ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138704</th>\n",
       "      <td>150522</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A1S3C5OFU508P3</td>\n",
       "      <td>Charles Ashbacher</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1219536000</td>\n",
       "      <td>Children will find it entertaining and a gener...</td>\n",
       "      <td>This book contains a collection of twelve shor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138705</th>\n",
       "      <td>150523</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A2P4F2UO0UMP8C</td>\n",
       "      <td>Elizabeth A. Curry \"Lovely Librarian\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1096675200</td>\n",
       "      <td>MMMM chicken soup....</td>\n",
       "      <td>Summary:  A young boy describes the usefulness...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138707</th>\n",
       "      <td>150525</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A2QID6VCFTY51R</td>\n",
       "      <td>Rick</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1025481600</td>\n",
       "      <td>In December it will be, my snowman's anniversa...</td>\n",
       "      <td>My daughter loves all the \"Really Rosie\" books...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138708</th>\n",
       "      <td>150526</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A3E9QZFE9KXH8J</td>\n",
       "      <td>R. Mitchell</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1129507200</td>\n",
       "      <td>awesome book poor size</td>\n",
       "      <td>This is one of the best children's books ever ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138709</th>\n",
       "      <td>150529</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A25ACLV5KPB4W</td>\n",
       "      <td>Matt Hetling \"Matt\"</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1108425600</td>\n",
       "      <td>Nice cadence, catchy rhymes</td>\n",
       "      <td>In June&lt;br /&gt;I saw a charming group&lt;br /&gt;of ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138699</th>\n",
       "      <td>150517</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>ABW4IC5G5G8B5</td>\n",
       "      <td>kevin clark</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1291075200</td>\n",
       "      <td>good for children</td>\n",
       "      <td>Classic children's book, can't go wrong. I rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138686</th>\n",
       "      <td>150504</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>AQEYF1AXARWJZ</td>\n",
       "      <td>Les Sinclair \"book maven\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1212278400</td>\n",
       "      <td>Chicken Soup with Rice</td>\n",
       "      <td>A very entertaining rhyming story--cleaver and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138692</th>\n",
       "      <td>150510</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>AM1MNZMYMS7D8</td>\n",
       "      <td>Dr. Joshua  Grossman</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1348358400</td>\n",
       "      <td>Professional Mentoring</td>\n",
       "      <td>TITLE: Chicken Soup with Rice&lt;br /&gt;AUTHOR: Mau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138680</th>\n",
       "      <td>150498</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A3SJWISOCP31TR</td>\n",
       "      <td>R. J. Wells</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1176336000</td>\n",
       "      <td>A Gem of a Book</td>\n",
       "      <td>This is a wonderful little book. I loved it 40...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138677</th>\n",
       "      <td>150494</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>AYZ0PR5QZROD1</td>\n",
       "      <td>Mother of 3 girls</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1173312000</td>\n",
       "      <td>Family favorite</td>\n",
       "      <td>All of my children love this book.  My first g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138678</th>\n",
       "      <td>150496</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A3KKR87BJ0C595</td>\n",
       "      <td>Gretchen Goodfellow \"Lover of children's lit\"</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1111363200</td>\n",
       "      <td>You'll use it once, you'll use it twice</td>\n",
       "      <td>One of my earliest memories is of this book.  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138685</th>\n",
       "      <td>150503</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A3R5XMPFU8YZ4D</td>\n",
       "      <td>Her Royal Motherliness \"Nana\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1233964800</td>\n",
       "      <td>so fun to read</td>\n",
       "      <td>This is my grand daughter's and my favorite bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138684</th>\n",
       "      <td>150502</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>AVFMJ50HNO21J</td>\n",
       "      <td>Jane Doe</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1324944000</td>\n",
       "      <td>Tiny little book, Wonderful little rhymes.</td>\n",
       "      <td>This copy is smaller than I expected (mostly b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138679</th>\n",
       "      <td>150497</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A1HKYQOFC8ZZCH</td>\n",
       "      <td>Maria Apolloni \"lanarossa\"</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1334707200</td>\n",
       "      <td>The story is great, the softcover book is disa...</td>\n",
       "      <td>I give five stars to the Maurice Sendak story....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178141</th>\n",
       "      <td>193170</td>\n",
       "      <td>B009RSR8HO</td>\n",
       "      <td>A1TNEJA68OD7ZH</td>\n",
       "      <td>morgan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350518400</td>\n",
       "      <td>Fat to Skinny Zero Sweetner</td>\n",
       "      <td>This is what I use when I'm baking instead of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178143</th>\n",
       "      <td>193172</td>\n",
       "      <td>B009RSR8HO</td>\n",
       "      <td>A3JJTHP8T7A8LY</td>\n",
       "      <td>Joanne Eklund \"Joanne\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350432000</td>\n",
       "      <td>Zero</td>\n",
       "      <td>FTS Zero is the best sweetener I have ever tri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178147</th>\n",
       "      <td>193176</td>\n",
       "      <td>B009RSR8HO</td>\n",
       "      <td>A76WHW051R3KV</td>\n",
       "      <td>Shawn \"Shawn\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350432000</td>\n",
       "      <td>My #1 Sweetener of choice</td>\n",
       "      <td>What a wonderful product! It's perfect to use ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178146</th>\n",
       "      <td>193175</td>\n",
       "      <td>B009RSR8HO</td>\n",
       "      <td>A1A0PMN417S4V9</td>\n",
       "      <td>mamaelle \"mamaelle\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350432000</td>\n",
       "      <td>YAY! No Dextrose!!</td>\n",
       "      <td>Packets of powdered sweeteners usually have a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178144</th>\n",
       "      <td>193173</td>\n",
       "      <td>B009RSR8HO</td>\n",
       "      <td>A34TVEXPHSSPBV</td>\n",
       "      <td>Beth</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350432000</td>\n",
       "      <td>Love it!</td>\n",
       "      <td>I love this sweetener.  I use it to replace su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178145</th>\n",
       "      <td>193174</td>\n",
       "      <td>B009RSR8HO</td>\n",
       "      <td>A4P6AN2L435PV</td>\n",
       "      <td>romarc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350432000</td>\n",
       "      <td>LOVE!!  LOVE!!</td>\n",
       "      <td>LOVE, LOVE this sweetener!!  I use it in all m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188339</th>\n",
       "      <td>204274</td>\n",
       "      <td>B009SA5NNW</td>\n",
       "      <td>A379KV6EQ66ZJR</td>\n",
       "      <td>Craig</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1347062400</td>\n",
       "      <td>Awesome Crisps!!! Arrived in just 8 days in Te...</td>\n",
       "      <td>These crisps are my favorite.  I ordered these...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188351</th>\n",
       "      <td>204286</td>\n",
       "      <td>B009SA5NNW</td>\n",
       "      <td>AVRU1Z8N59UZV</td>\n",
       "      <td>LIsa Fresch</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1349654400</td>\n",
       "      <td>Walkers Crisps 6 pack</td>\n",
       "      <td>I ordered this product on Amazon to get some o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188349</th>\n",
       "      <td>204284</td>\n",
       "      <td>B009SA5NNW</td>\n",
       "      <td>A2SB8DPH72UOM7</td>\n",
       "      <td>Tim C.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1317600000</td>\n",
       "      <td>Yum!</td>\n",
       "      <td>Bought these the other day while I was in Cana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188348</th>\n",
       "      <td>204283</td>\n",
       "      <td>B009SA5NNW</td>\n",
       "      <td>A2QXG1QOV4MTVL</td>\n",
       "      <td>Wordup \"Wordup2you\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1321920000</td>\n",
       "      <td>Stale Chips</td>\n",
       "      <td>Item came promptly however the crisps were 3 m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188347</th>\n",
       "      <td>204282</td>\n",
       "      <td>B009SA5NNW</td>\n",
       "      <td>A373QMETEUKMS7</td>\n",
       "      <td>Rebecca Wade</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1327017600</td>\n",
       "      <td>Excellent!</td>\n",
       "      <td>The crisps are awesome. Give me English crisps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188346</th>\n",
       "      <td>204281</td>\n",
       "      <td>B009SA5NNW</td>\n",
       "      <td>A3CBCI8ZU6A9XM</td>\n",
       "      <td>Cody B.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1328486400</td>\n",
       "      <td>Cody B.</td>\n",
       "      <td>I loved the chips they were AWESOME!!! but tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188340</th>\n",
       "      <td>204275</td>\n",
       "      <td>B009SA5NNW</td>\n",
       "      <td>A1XPE0WCC6RYVO</td>\n",
       "      <td>AnthonyT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1344988800</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>These are the best flavor chips, my daughter a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188345</th>\n",
       "      <td>204280</td>\n",
       "      <td>B009SA5NNW</td>\n",
       "      <td>AI1G344L7R1TN</td>\n",
       "      <td>Brian M. Schissler</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1332979200</td>\n",
       "      <td>WOW.....</td>\n",
       "      <td>This could possibly be the best tasting chip I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188343</th>\n",
       "      <td>204278</td>\n",
       "      <td>B009SA5NNW</td>\n",
       "      <td>A3M922QSBYYXR</td>\n",
       "      <td>Jeannie Jordahl</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1335744000</td>\n",
       "      <td>These were amazing!</td>\n",
       "      <td>This chips kind of reminded me of bacon bits. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188336</th>\n",
       "      <td>204271</td>\n",
       "      <td>B009SA5NNW</td>\n",
       "      <td>A133WGB2RLKB1T</td>\n",
       "      <td>Temple Gordon</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1321228800</td>\n",
       "      <td>Walkers smkey bacon crisps</td>\n",
       "      <td>These are amazing chips but they just cost too...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188337</th>\n",
       "      <td>204272</td>\n",
       "      <td>B009SA5NNW</td>\n",
       "      <td>AWFA8N9IXELVH</td>\n",
       "      <td>No Pen Name</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1351123200</td>\n",
       "      <td>Deceptive description</td>\n",
       "      <td>On Oct 9 I ordered from a different vendor the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188342</th>\n",
       "      <td>204277</td>\n",
       "      <td>B009SA5NNW</td>\n",
       "      <td>A2TWDT92R8VPTI</td>\n",
       "      <td>d wilson \"Visitor from a Perpendicular Universe\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1337904000</td>\n",
       "      <td>Tastes just like bacon!</td>\n",
       "      <td>I had a bag of these during a trip to London. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188338</th>\n",
       "      <td>204273</td>\n",
       "      <td>B009SA5NNW</td>\n",
       "      <td>AG4YGLLIE8BWP</td>\n",
       "      <td>Miwintee</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1351123200</td>\n",
       "      <td>Makes me drool just thinking of them</td>\n",
       "      <td>The Brit's have out done us. The flavor is sup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188341</th>\n",
       "      <td>204276</td>\n",
       "      <td>B009SA5NNW</td>\n",
       "      <td>A3U0YIPTZX8DZ4</td>\n",
       "      <td>vee</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1339977600</td>\n",
       "      <td>Re-Rating</td>\n",
       "      <td>Okay, I jumped the gun, because they were send...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188344</th>\n",
       "      <td>204279</td>\n",
       "      <td>B009SA5NNW</td>\n",
       "      <td>A1PVBIUKEDNGVP</td>\n",
       "      <td>Steve L</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1333843200</td>\n",
       "      <td>One Word, \"YUM!\"</td>\n",
       "      <td>If you like salt and vinegar crisps (chips), b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188350</th>\n",
       "      <td>204285</td>\n",
       "      <td>B009SA5NNW</td>\n",
       "      <td>A2XNO53D6J6322</td>\n",
       "      <td>dragenfli254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1317081600</td>\n",
       "      <td>Delish!</td>\n",
       "      <td>I had these wonderful chips in Ireland a few y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173675</th>\n",
       "      <td>188389</td>\n",
       "      <td>B009SF0TN6</td>\n",
       "      <td>A1L0GWGRK4BYPT</td>\n",
       "      <td>Bety Robinson</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350518400</td>\n",
       "      <td>Amazing!! Great sauce for everything!</td>\n",
       "      <td>You have to try this sauce to believe it! It s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208554</th>\n",
       "      <td>226019</td>\n",
       "      <td>B009SMKESO</td>\n",
       "      <td>A35K4XT7T1ZIFU</td>\n",
       "      <td>Inez Rivera</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1304985600</td>\n",
       "      <td>Not a bad product.</td>\n",
       "      <td>This review is for the boneless ham. A little ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204727</th>\n",
       "      <td>221795</td>\n",
       "      <td>B009SR4OQ2</td>\n",
       "      <td>A32A6X5KCP7ARG</td>\n",
       "      <td>sicamar</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1350604800</td>\n",
       "      <td>Awesome Taste</td>\n",
       "      <td>I bought this Hazelnut Paste (Nocciola Spread)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176791</th>\n",
       "      <td>191721</td>\n",
       "      <td>B009UOFTUI</td>\n",
       "      <td>AJVB004EB0MVK</td>\n",
       "      <td>D. Christofferson</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1345852800</td>\n",
       "      <td>weak coffee not good for a premium product and...</td>\n",
       "      <td>This coffee supposedly is premium, it tastes w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>1478</td>\n",
       "      <td>B009UOFU20</td>\n",
       "      <td>AJVB004EB0MVK</td>\n",
       "      <td>D. Christofferson</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1345852800</td>\n",
       "      <td>weak coffee not good for a premium product and...</td>\n",
       "      <td>This coffee supposedly is premium, it tastes w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303285</th>\n",
       "      <td>328482</td>\n",
       "      <td>B009UUS05I</td>\n",
       "      <td>ARL20DSHGVM1Y</td>\n",
       "      <td>Jamie</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1331856000</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>The basket was the perfect sympathy gift when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5259</th>\n",
       "      <td>5703</td>\n",
       "      <td>B009WSNWC4</td>\n",
       "      <td>AMP7K1O84DH1T</td>\n",
       "      <td>ESTY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1351209600</td>\n",
       "      <td>DELICIOUS</td>\n",
       "      <td>Purchased this product at a local store in NY ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302474</th>\n",
       "      <td>327601</td>\n",
       "      <td>B009WVB40S</td>\n",
       "      <td>A3ME78KVX31T21</td>\n",
       "      <td>K'la</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1351123200</td>\n",
       "      <td>Tasty!</td>\n",
       "      <td>I purchased this to send to my son who's away ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>525814 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId  \\\n",
       "138706  150524  0006641040   ACITT7DI6IDDL   \n",
       "138688  150506  0006641040  A2IW4PEEKO2R0U   \n",
       "138689  150507  0006641040  A1S4A3IQ2MU7V4   \n",
       "138690  150508  0006641040     AZGXZ2UUK6X   \n",
       "138691  150509  0006641040  A3CMRKGE0P909G   \n",
       "138693  150511  0006641040  A1C9K534BCI9GO   \n",
       "138694  150512  0006641040  A1DJXZA5V5FFVA   \n",
       "138695  150513  0006641040   ASH0DZQQF6AIZ   \n",
       "138696  150514  0006641040   A2ONB6ZA292PA   \n",
       "138697  150515  0006641040  A2RTT81R6Y3R7X   \n",
       "138687  150505  0006641040  A2PTSM496CF40Z   \n",
       "138698  150516  0006641040  A3OI7ZGH6WZJ5G   \n",
       "138700  150518  0006641040   AK1L4EJBA23JF   \n",
       "138701  150519  0006641040  A12HY5OZ2QNK4N   \n",
       "138702  150520  0006641040   ADBFSA9KTQANE   \n",
       "138703  150521  0006641040  A3RMCRB2NDTDYP   \n",
       "138704  150522  0006641040  A1S3C5OFU508P3   \n",
       "138705  150523  0006641040  A2P4F2UO0UMP8C   \n",
       "138707  150525  0006641040  A2QID6VCFTY51R   \n",
       "138708  150526  0006641040  A3E9QZFE9KXH8J   \n",
       "138709  150529  0006641040   A25ACLV5KPB4W   \n",
       "138699  150517  0006641040   ABW4IC5G5G8B5   \n",
       "138686  150504  0006641040   AQEYF1AXARWJZ   \n",
       "138692  150510  0006641040   AM1MNZMYMS7D8   \n",
       "138680  150498  0006641040  A3SJWISOCP31TR   \n",
       "138677  150494  0006641040   AYZ0PR5QZROD1   \n",
       "138678  150496  0006641040  A3KKR87BJ0C595   \n",
       "138685  150503  0006641040  A3R5XMPFU8YZ4D   \n",
       "138684  150502  0006641040   AVFMJ50HNO21J   \n",
       "138679  150497  0006641040  A1HKYQOFC8ZZCH   \n",
       "...        ...         ...             ...   \n",
       "178141  193170  B009RSR8HO  A1TNEJA68OD7ZH   \n",
       "178143  193172  B009RSR8HO  A3JJTHP8T7A8LY   \n",
       "178147  193176  B009RSR8HO   A76WHW051R3KV   \n",
       "178146  193175  B009RSR8HO  A1A0PMN417S4V9   \n",
       "178144  193173  B009RSR8HO  A34TVEXPHSSPBV   \n",
       "178145  193174  B009RSR8HO   A4P6AN2L435PV   \n",
       "188339  204274  B009SA5NNW  A379KV6EQ66ZJR   \n",
       "188351  204286  B009SA5NNW   AVRU1Z8N59UZV   \n",
       "188349  204284  B009SA5NNW  A2SB8DPH72UOM7   \n",
       "188348  204283  B009SA5NNW  A2QXG1QOV4MTVL   \n",
       "188347  204282  B009SA5NNW  A373QMETEUKMS7   \n",
       "188346  204281  B009SA5NNW  A3CBCI8ZU6A9XM   \n",
       "188340  204275  B009SA5NNW  A1XPE0WCC6RYVO   \n",
       "188345  204280  B009SA5NNW   AI1G344L7R1TN   \n",
       "188343  204278  B009SA5NNW   A3M922QSBYYXR   \n",
       "188336  204271  B009SA5NNW  A133WGB2RLKB1T   \n",
       "188337  204272  B009SA5NNW   AWFA8N9IXELVH   \n",
       "188342  204277  B009SA5NNW  A2TWDT92R8VPTI   \n",
       "188338  204273  B009SA5NNW   AG4YGLLIE8BWP   \n",
       "188341  204276  B009SA5NNW  A3U0YIPTZX8DZ4   \n",
       "188344  204279  B009SA5NNW  A1PVBIUKEDNGVP   \n",
       "188350  204285  B009SA5NNW  A2XNO53D6J6322   \n",
       "173675  188389  B009SF0TN6  A1L0GWGRK4BYPT   \n",
       "208554  226019  B009SMKESO  A35K4XT7T1ZIFU   \n",
       "204727  221795  B009SR4OQ2  A32A6X5KCP7ARG   \n",
       "176791  191721  B009UOFTUI   AJVB004EB0MVK   \n",
       "1362      1478  B009UOFU20   AJVB004EB0MVK   \n",
       "303285  328482  B009UUS05I   ARL20DSHGVM1Y   \n",
       "5259      5703  B009WSNWC4   AMP7K1O84DH1T   \n",
       "302474  327601  B009WVB40S  A3ME78KVX31T21   \n",
       "\n",
       "                                             ProfileName  \\\n",
       "138706                                   shari zychinski   \n",
       "138688                                             Tracy   \n",
       "138689                             sally sue \"sally sue\"   \n",
       "138690                       Catherine Hallberg \"(Kate)\"   \n",
       "138691                                            Teresa   \n",
       "138693                                Laura Purdie Salas   \n",
       "138694                                         A. Conway   \n",
       "138695                                          tessarat   \n",
       "138696                                  Rosalind Matzner   \n",
       "138697                                           Lindylu   \n",
       "138687  Jason A. Teeple \"Nobody made a greater mistak...   \n",
       "138698                       Mary Jane Rogers \"Maedchen\"   \n",
       "138700                                       L. M. Kraus   \n",
       "138701                             Elizabeth H. Roessner   \n",
       "138702                    James L. Hammock \"Pucks Buddy\"   \n",
       "138703                                  Carol Carruthers   \n",
       "138704                                 Charles Ashbacher   \n",
       "138705             Elizabeth A. Curry \"Lovely Librarian\"   \n",
       "138707                                              Rick   \n",
       "138708                                       R. Mitchell   \n",
       "138709                               Matt Hetling \"Matt\"   \n",
       "138699                                       kevin clark   \n",
       "138686                         Les Sinclair \"book maven\"   \n",
       "138692                              Dr. Joshua  Grossman   \n",
       "138680                                       R. J. Wells   \n",
       "138677                                 Mother of 3 girls   \n",
       "138678     Gretchen Goodfellow \"Lover of children's lit\"   \n",
       "138685                     Her Royal Motherliness \"Nana\"   \n",
       "138684                                          Jane Doe   \n",
       "138679                        Maria Apolloni \"lanarossa\"   \n",
       "...                                                  ...   \n",
       "178141                                            morgan   \n",
       "178143                            Joanne Eklund \"Joanne\"   \n",
       "178147                                     Shawn \"Shawn\"   \n",
       "178146                               mamaelle \"mamaelle\"   \n",
       "178144                                              Beth   \n",
       "178145                                            romarc   \n",
       "188339                                             Craig   \n",
       "188351                                       LIsa Fresch   \n",
       "188349                                            Tim C.   \n",
       "188348                               Wordup \"Wordup2you\"   \n",
       "188347                                      Rebecca Wade   \n",
       "188346                                           Cody B.   \n",
       "188340                                          AnthonyT   \n",
       "188345                                Brian M. Schissler   \n",
       "188343                                   Jeannie Jordahl   \n",
       "188336                                     Temple Gordon   \n",
       "188337                                       No Pen Name   \n",
       "188342  d wilson \"Visitor from a Perpendicular Universe\"   \n",
       "188338                                          Miwintee   \n",
       "188341                                               vee   \n",
       "188344                                           Steve L   \n",
       "188350                                      dragenfli254   \n",
       "173675                                     Bety Robinson   \n",
       "208554                                       Inez Rivera   \n",
       "204727                                           sicamar   \n",
       "176791                                 D. Christofferson   \n",
       "1362                                   D. Christofferson   \n",
       "303285                                             Jamie   \n",
       "5259                                                ESTY   \n",
       "302474                                              K'la   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "138706                     0                       0      5   939340800   \n",
       "138688                     1                       1      4  1194739200   \n",
       "138689                     1                       1      4  1191456000   \n",
       "138690                     1                       1      5  1076025600   \n",
       "138691                     3                       4      5  1018396800   \n",
       "138693                     0                       0      4  1344211200   \n",
       "138694                     0                       0      5  1338249600   \n",
       "138695                     0                       0      5  1325721600   \n",
       "138696                     0                       0      5  1313884800   \n",
       "138697                     0                       0      5  1303171200   \n",
       "138687                     1                       1      4  1210809600   \n",
       "138698                     0                       0      5  1293840000   \n",
       "138700                     0                       0      5  1288224000   \n",
       "138701                     0                       0      5  1256774400   \n",
       "138702                     0                       0      5  1256688000   \n",
       "138703                     0                       0      5  1243468800   \n",
       "138704                     0                       0      4  1219536000   \n",
       "138705                     0                       0      4  1096675200   \n",
       "138707                     1                       2      5  1025481600   \n",
       "138708                    11                      18      1  1129507200   \n",
       "138709                     0                       1      4  1108425600   \n",
       "138699                     0                       0      5  1291075200   \n",
       "138686                     1                       1      4  1212278400   \n",
       "138692                     0                       0      5  1348358400   \n",
       "138680                     2                       2      5  1176336000   \n",
       "138677                     3                       3      5  1173312000   \n",
       "138678                     3                       3      5  1111363200   \n",
       "138685                     1                       1      5  1233964800   \n",
       "138684                     1                       1      4  1324944000   \n",
       "138679                     2                       2      1  1334707200   \n",
       "...                      ...                     ...    ...         ...   \n",
       "178141                     0                       0      5  1350518400   \n",
       "178143                     0                       0      5  1350432000   \n",
       "178147                     0                       0      5  1350432000   \n",
       "178146                     0                       0      5  1350432000   \n",
       "178144                     0                       0      5  1350432000   \n",
       "178145                     0                       0      5  1350432000   \n",
       "188339                     0                       0      5  1347062400   \n",
       "188351                     0                       1      1  1349654400   \n",
       "188349                     0                       0      4  1317600000   \n",
       "188348                     0                       0      1  1321920000   \n",
       "188347                     0                       0      4  1327017600   \n",
       "188346                     0                       0      5  1328486400   \n",
       "188340                     0                       0      5  1344988800   \n",
       "188345                     0                       0      4  1332979200   \n",
       "188343                     0                       0      5  1335744000   \n",
       "188336                     1                       1      4  1321228800   \n",
       "188337                     0                       0      1  1351123200   \n",
       "188342                     0                       0      5  1337904000   \n",
       "188338                     0                       0      5  1351123200   \n",
       "188341                     0                       0      4  1339977600   \n",
       "188344                     0                       0      5  1333843200   \n",
       "188350                     0                       0      5  1317081600   \n",
       "173675                     0                       0      5  1350518400   \n",
       "208554                     0                       1      4  1304985600   \n",
       "204727                     1                       1      5  1350604800   \n",
       "176791                     0                       0      1  1345852800   \n",
       "1362                       0                       0      1  1345852800   \n",
       "303285                     0                       0      5  1331856000   \n",
       "5259                       0                       0      5  1351209600   \n",
       "302474                     0                       0      5  1351123200   \n",
       "\n",
       "                                                  Summary  \\\n",
       "138706                          EVERY book is educational   \n",
       "138688         Love the book, miss the hard cover version   \n",
       "138689                      chicken soup with rice months   \n",
       "138690             a good swingy rhythm for reading aloud   \n",
       "138691                    A great way to learn the months   \n",
       "138693                             Charming and childlike   \n",
       "138694                                         Must have.   \n",
       "138695                                          A classic   \n",
       "138696                             Chicken soup with Rice   \n",
       "138697                 One of our family's favorite books   \n",
       "138687                                          A classic   \n",
       "138698                                           Darling!   \n",
       "138700                                     love this book   \n",
       "138701                                 It's a great book!   \n",
       "138702                                         Great Gift   \n",
       "138703                                This book is great!   \n",
       "138704  Children will find it entertaining and a gener...   \n",
       "138705                              MMMM chicken soup....   \n",
       "138707  In December it will be, my snowman's anniversa...   \n",
       "138708                             awesome book poor size   \n",
       "138709                        Nice cadence, catchy rhymes   \n",
       "138699                                  good for children   \n",
       "138686                             Chicken Soup with Rice   \n",
       "138692                             Professional Mentoring   \n",
       "138680                                    A Gem of a Book   \n",
       "138677                                    Family favorite   \n",
       "138678            You'll use it once, you'll use it twice   \n",
       "138685                                     so fun to read   \n",
       "138684         Tiny little book, Wonderful little rhymes.   \n",
       "138679  The story is great, the softcover book is disa...   \n",
       "...                                                   ...   \n",
       "178141                        Fat to Skinny Zero Sweetner   \n",
       "178143                                               Zero   \n",
       "178147                          My #1 Sweetener of choice   \n",
       "178146                                 YAY! No Dextrose!!   \n",
       "178144                                           Love it!   \n",
       "178145                                     LOVE!!  LOVE!!   \n",
       "188339  Awesome Crisps!!! Arrived in just 8 days in Te...   \n",
       "188351                              Walkers Crisps 6 pack   \n",
       "188349                                               Yum!   \n",
       "188348                                        Stale Chips   \n",
       "188347                                         Excellent!   \n",
       "188346                                            Cody B.   \n",
       "188340                                          Excellent   \n",
       "188345                                           WOW.....   \n",
       "188343                                These were amazing!   \n",
       "188336                         Walkers smkey bacon crisps   \n",
       "188337                              Deceptive description   \n",
       "188342                            Tastes just like bacon!   \n",
       "188338               Makes me drool just thinking of them   \n",
       "188341                                          Re-Rating   \n",
       "188344                                   One Word, \"YUM!\"   \n",
       "188350                                            Delish!   \n",
       "173675              Amazing!! Great sauce for everything!   \n",
       "208554                                 Not a bad product.   \n",
       "204727                                      Awesome Taste   \n",
       "176791  weak coffee not good for a premium product and...   \n",
       "1362    weak coffee not good for a premium product and...   \n",
       "303285                                            Perfect   \n",
       "5259                                            DELICIOUS   \n",
       "302474                                             Tasty!   \n",
       "\n",
       "                                                     Text  \n",
       "138706  this witty little book makes my son laugh at l...  \n",
       "138688  I grew up reading these Sendak books, and watc...  \n",
       "138689  This is a fun way for children to learn their ...  \n",
       "138690  This is a great little book to read aloud- it ...  \n",
       "138691  This is a book of poetry about the months of t...  \n",
       "138693  A charming, rhyming book that describes the ci...  \n",
       "138694  I set aside at least an hour each day to read ...  \n",
       "138695  I remembered this book from my childhood and g...  \n",
       "138696  It's a great book with adorable illustrations....  \n",
       "138697  This book is a family favorite and was read to...  \n",
       "138687  Get the movie or sound track and sing along wi...  \n",
       "138698  The same author wrote \"Where the Wild Things A...  \n",
       "138700  Great book, perfect condition arrived in a sho...  \n",
       "138701  I've always loved chicken soup and rice. My la...  \n",
       "138702  This book was purchased as a birthday gift for...  \n",
       "138703  My 7 year old daughter brought this book home ...  \n",
       "138704  This book contains a collection of twelve shor...  \n",
       "138705  Summary:  A young boy describes the usefulness...  \n",
       "138707  My daughter loves all the \"Really Rosie\" books...  \n",
       "138708  This is one of the best children's books ever ...  \n",
       "138709  In June<br />I saw a charming group<br />of ro...  \n",
       "138699  Classic children's book, can't go wrong. I rea...  \n",
       "138686  A very entertaining rhyming story--cleaver and...  \n",
       "138692  TITLE: Chicken Soup with Rice<br />AUTHOR: Mau...  \n",
       "138680  This is a wonderful little book. I loved it 40...  \n",
       "138677  All of my children love this book.  My first g...  \n",
       "138678  One of my earliest memories is of this book.  ...  \n",
       "138685  This is my grand daughter's and my favorite bo...  \n",
       "138684  This copy is smaller than I expected (mostly b...  \n",
       "138679  I give five stars to the Maurice Sendak story....  \n",
       "...                                                   ...  \n",
       "178141  This is what I use when I'm baking instead of ...  \n",
       "178143  FTS Zero is the best sweetener I have ever tri...  \n",
       "178147  What a wonderful product! It's perfect to use ...  \n",
       "178146  Packets of powdered sweeteners usually have a ...  \n",
       "178144  I love this sweetener.  I use it to replace su...  \n",
       "178145  LOVE, LOVE this sweetener!!  I use it in all m...  \n",
       "188339  These crisps are my favorite.  I ordered these...  \n",
       "188351  I ordered this product on Amazon to get some o...  \n",
       "188349  Bought these the other day while I was in Cana...  \n",
       "188348  Item came promptly however the crisps were 3 m...  \n",
       "188347  The crisps are awesome. Give me English crisps...  \n",
       "188346  I loved the chips they were AWESOME!!! but tha...  \n",
       "188340  These are the best flavor chips, my daughter a...  \n",
       "188345  This could possibly be the best tasting chip I...  \n",
       "188343  This chips kind of reminded me of bacon bits. ...  \n",
       "188336  These are amazing chips but they just cost too...  \n",
       "188337  On Oct 9 I ordered from a different vendor the...  \n",
       "188342  I had a bag of these during a trip to London. ...  \n",
       "188338  The Brit's have out done us. The flavor is sup...  \n",
       "188341  Okay, I jumped the gun, because they were send...  \n",
       "188344  If you like salt and vinegar crisps (chips), b...  \n",
       "188350  I had these wonderful chips in Ireland a few y...  \n",
       "173675  You have to try this sauce to believe it! It s...  \n",
       "208554  This review is for the boneless ham. A little ...  \n",
       "204727  I bought this Hazelnut Paste (Nocciola Spread)...  \n",
       "176791  This coffee supposedly is premium, it tastes w...  \n",
       "1362    This coffee supposedly is premium, it tastes w...  \n",
       "303285  The basket was the perfect sympathy gift when ...  \n",
       "5259    Purchased this product at a local store in NY ...  \n",
       "302474  I purchased this to send to my son who's away ...  \n",
       "\n",
       "[525814 rows x 10 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sorting data according to ProductId in ascending order\n",
    "sorted_data=filtered_data.sort_values('ProductId', axis=0, \n",
    "ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
    "sorted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8b-O13XVCAZZ",
    "outputId": "12b254d4-826d-4cfc-bb6d-455f4d5b2a4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364173, 10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Deduplication of entries\n",
    "final=sorted_data.drop_duplicates(subset={\"UserId\",\n",
    "            \"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=False)\n",
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S72Yh-rHCAZc",
    "outputId": "146c067f-081c-4e26-f527-71442ff83b8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.25890143662969"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking to see how much % of data still remains\n",
    "(final['Id'].size*1.0)/(filtered_data['Id'].size*1.0)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LO5nLKeFCAZf"
   },
   "source": [
    "<b>Observation:-</b> It was also seen that in two rows given below the value of HelpfulnessNumerator is greater than HelpfulnessDenominator which is not practically possible hence these two rows too are removed from calcualtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L9z5lrsiCAZh",
    "outputId": "1a0dfa7c-62f4-4469-a97b-38f77fa3b2ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64422</td>\n",
       "      <td>B000MIDROQ</td>\n",
       "      <td>A161DK06JJMCYF</td>\n",
       "      <td>J. E. Stephens \"Jeanne\"</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1224892800</td>\n",
       "      <td>Bought This for My Son at College</td>\n",
       "      <td>My son loves spaghetti so I didn't hesitate or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44737</td>\n",
       "      <td>B001EQ55RW</td>\n",
       "      <td>A2V0I904FH7ABY</td>\n",
       "      <td>Ram</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1212883200</td>\n",
       "      <td>Pure cocoa taste with crunchy almonds inside</td>\n",
       "      <td>It was almost a 'love at first bite' - the per...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id   ProductId          UserId              ProfileName  \\\n",
       "0  64422  B000MIDROQ  A161DK06JJMCYF  J. E. Stephens \"Jeanne\"   \n",
       "1  44737  B001EQ55RW  A2V0I904FH7ABY                      Ram   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     3                       1      5  1224892800   \n",
       "1                     3                       2      4  1212883200   \n",
       "\n",
       "                                        Summary  \\\n",
       "0             Bought This for My Son at College   \n",
       "1  Pure cocoa taste with crunchy almonds inside   \n",
       "\n",
       "                                                Text  \n",
       "0  My son loves spaghetti so I didn't hesitate or...  \n",
       "1  It was almost a 'love at first bite' - the per...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display= pd.read_sql_query(\"\"\"\n",
    "SELECT *\n",
    "FROM Reviews\n",
    "WHERE Score != 3 AND Id=44737 OR Id=64422\n",
    "ORDER BY ProductID\n",
    "\"\"\", con)\n",
    "\n",
    "display.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Tphk1piCAZk"
   },
   "outputs": [],
   "source": [
    "final=final[final.HelpfulnessNumerator<=final.HelpfulnessDenominator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8TpsGDdJCAZm",
    "outputId": "287c6c08-d222-4848-b677-c9a5e769d0b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364171, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5    250965\n",
       "4     56096\n",
       "1     36307\n",
       "2     20803\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Before starting the next phase of preprocessing lets see the number of entries left\n",
    "print(final.shape)\n",
    "\n",
    "#How many positive and negative reviews are present in our dataset?\n",
    "final['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RxBsuBylCAZr"
   },
   "source": [
    "# [3].  Text Preprocessing.\n",
    "\n",
    "Now that we have finished deduplication our data requires some preprocessing before we go on further with analysis and making the prediction model.\n",
    "\n",
    "Hence in the Preprocessing phase we do the following in the order below:-\n",
    "\n",
    "1. Begin by removing the html tags\n",
    "2. Remove any punctuations or limited set of special characters like , or . or # etc.\n",
    "3. Check if the word is made up of english letters and is not alpha-numeric\n",
    "4. Check to see if the length of the word is greater than 2 (as it was researched that there is no adjective in 2-letters)\n",
    "5. Convert the word to lowercase\n",
    "6. Remove Stopwords\n",
    "7. Finally Snowball Stemming the word (it was obsereved to be better than Porter Stemming)<br>\n",
    "\n",
    "After which we collect the words used to describe positive and negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "laOGMFB7CAZt",
    "outputId": "49d82795-cea4-4695-9834-45978266f6f4"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-fc290a601444>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# printing some random reviews\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msent_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent_0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"=\"\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final' is not defined"
     ]
    }
   ],
   "source": [
    "# printing some random reviews\n",
    "sent_0 = final['Text'].values[0]\n",
    "print(sent_0)\n",
    "print(\"=\"*50)\n",
    "\n",
    "sent_1000 = final['Text'].values[1000]\n",
    "print(sent_1000)\n",
    "print(\"=\"*50)\n",
    "\n",
    "sent_1500 = final['Text'].values[1500]\n",
    "print(sent_1500)\n",
    "print(\"=\"*50)\n",
    "\n",
    "sent_4900 = final['Text'].values[4900]\n",
    "print(sent_4900)\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MvD0JaQ9CAZx",
    "outputId": "dcc683d4-6014-4430-fb91-f9526bca4475"
   },
   "outputs": [],
   "source": [
    "# remove urls from text python: https://stackoverflow.com/a/40823105/4084039\n",
    "sent_0 = re.sub(r\"http\\S+\", \"\", sent_0)\n",
    "sent_1000 = re.sub(r\"http\\S+\", \"\", sent_1000)\n",
    "sent_150 = re.sub(r\"http\\S+\", \"\", sent_1500)\n",
    "sent_4900 = re.sub(r\"http\\S+\", \"\", sent_4900)\n",
    "\n",
    "print(sent_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Liu2zNFLCAZ0",
    "outputId": "f66770ef-17d3-4a99-df7f-75242858701d"
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/16206380/python-beautifulsoup-how-to-remove-all-tags-from-an-element\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(sent_0, 'lxml')\n",
    "text = soup.get_text()\n",
    "print(text)\n",
    "print(\"=\"*50)\n",
    "\n",
    "soup = BeautifulSoup(sent_1000, 'lxml')\n",
    "text = soup.get_text()\n",
    "print(text)\n",
    "print(\"=\"*50)\n",
    "\n",
    "soup = BeautifulSoup(sent_1500, 'lxml')\n",
    "text = soup.get_text()\n",
    "print(text)\n",
    "print(\"=\"*50)\n",
    "\n",
    "soup = BeautifulSoup(sent_4900, 'lxml')\n",
    "text = soup.get_text()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lNHWbzBaCAZ3"
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/47091490/4084039\n",
    "import re\n",
    "\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y7v1fmngCAZ5",
    "outputId": "22e3fcb6-c2e6-4c92-be48-f65543b1140f"
   },
   "outputs": [],
   "source": [
    "sent_1500 = decontracted(sent_1500)\n",
    "print(sent_1500)\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jKIBLrAjCAZ7",
    "outputId": "376f1e55-511a-4352-c345-a39f1d2a2224"
   },
   "outputs": [],
   "source": [
    "#remove words with numbers python: https://stackoverflow.com/a/18082370/4084039\n",
    "sent_0 = re.sub(\"\\S*\\d\\S*\", \"\", sent_0).strip()\n",
    "print(sent_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sU3eY6geCAZ9",
    "outputId": "90d91c93-0d77-47c0-e496-77d1611a86fb"
   },
   "outputs": [],
   "source": [
    "#remove spacial character: https://stackoverflow.com/a/5843547/4084039\n",
    "sent_1500 = re.sub('[^A-Za-z0-9]+', ' ', sent_1500)\n",
    "print(sent_1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xsr4xHkJCAaA"
   },
   "outputs": [],
   "source": [
    "# https://gist.github.com/sebleier/554280\n",
    "# we are removing the words from the stop words list: 'no', 'nor', 'not'\n",
    "# <br /><br /> ==> after the above steps, we are getting \"br br\"\n",
    "# we are including them into stop words list\n",
    "# instead of <br /> if we have <br/> these tags would have revmoved in the 1st step\n",
    "\n",
    "stopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MgsJ09NpCAaB",
    "outputId": "1d7ef7e7-d03e-4bff-850a-a2aef70af7d9"
   },
   "outputs": [],
   "source": [
    "# Combining all the above stundents \n",
    "from tqdm import tqdm\n",
    "preprocessed_reviews = []\n",
    "# tqdm is for printing the status bar\n",
    "for sentance in tqdm(final['Text'].values):\n",
    "    sentance = re.sub(r\"http\\S+\", \"\", sentance)\n",
    "    sentance = BeautifulSoup(sentance, 'lxml').get_text()\n",
    "    sentance = decontracted(sentance)\n",
    "    sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip()\n",
    "    sentance = re.sub('[^A-Za-z]+', ' ', sentance)\n",
    "    # https://gist.github.com/sebleier/554280\n",
    "    sentance = ' '.join(e.lower() for e in sentance.split() if e.lower() not in stopwords)\n",
    "    preprocessed_reviews.append(sentance.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f_zfwXXWCAaE",
    "outputId": "a8ba4cbf-3a4c-4447-f06a-2b639e1a5f88"
   },
   "outputs": [],
   "source": [
    "preprocessed_reviews[1500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tmeU-LoVCAaI"
   },
   "source": [
    "<h2><font color='red'>[3.2] Preprocess Summary</font></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wtJ2hcy9CAaI"
   },
   "outputs": [],
   "source": [
    "## Similartly you can do preprocessing for review summary also."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ytBZVEs2CAaL"
   },
   "source": [
    "# [4] Featurization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9amw6tMZCAaL"
   },
   "source": [
    "## [4.1] BAG OF WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3hasoJ-_CAaN",
    "outputId": "12aa3f3f-083c-4de4-a6e7-3dbde6b5a905"
   },
   "outputs": [],
   "source": [
    "#BoW\n",
    "count_vect = CountVectorizer() #in scikit-learn\n",
    "count_vect.fit(preprocessed_reviews)\n",
    "print(\"some feature names \", count_vect.get_feature_names()[:10])\n",
    "print('='*50)\n",
    "\n",
    "final_counts = count_vect.transform(preprocessed_reviews)\n",
    "print(\"the type of count vectorizer \",type(final_counts))\n",
    "print(\"the shape of out text BOW vectorizer \",final_counts.get_shape())\n",
    "print(\"the number of unique words \", final_counts.get_shape()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1dhfJZ7ZCAaR"
   },
   "source": [
    "## [4.2] Bi-Grams and n-Grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u1Ma2LBfCAaR",
    "outputId": "a5208a4c-c0ad-4360-f021-b2e8715610a4"
   },
   "outputs": [],
   "source": [
    "#bi-gram, tri-gram and n-gram\n",
    "\n",
    "#removing stop words like \"not\" should be avoided before building n-grams\n",
    "# count_vect = CountVectorizer(ngram_range=(1,2))\n",
    "# please do read the CountVectorizer documentation http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "# you can choose these numebrs min_df=10, max_features=5000, of your choice\n",
    "count_vect = CountVectorizer(ngram_range=(1,2), min_df=10, max_features=5000)\n",
    "final_bigram_counts = count_vect.fit_transform(preprocessed_reviews)\n",
    "print(\"the type of count vectorizer \",type(final_bigram_counts))\n",
    "print(\"the shape of out text BOW vectorizer \",final_bigram_counts.get_shape())\n",
    "print(\"the number of unique words including both unigrams and bigrams \", final_bigram_counts.get_shape()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F--Xk5fhCAaV"
   },
   "source": [
    "## [4.3] TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6heiZFZ-CAaW",
    "outputId": "08103e90-4bd8-410e-b3dc-84a02e01aa33"
   },
   "outputs": [],
   "source": [
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2), min_df=10)\n",
    "tf_idf_vect.fit(preprocessed_reviews)\n",
    "print(\"some sample features(unique words in the corpus)\",tf_idf_vect.get_feature_names()[0:10])\n",
    "print('='*50)\n",
    "\n",
    "final_tf_idf = tf_idf_vect.transform(preprocessed_reviews)\n",
    "print(\"the type of count vectorizer \",type(final_tf_idf))\n",
    "print(\"the shape of out text TFIDF vectorizer \",final_tf_idf.get_shape())\n",
    "print(\"the number of unique words including both unigrams and bigrams \", final_tf_idf.get_shape()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XnzP-eZdCAaa"
   },
   "source": [
    "## [4.4] Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e-IuUZsTCAaa"
   },
   "outputs": [],
   "source": [
    "# Train your own Word2Vec model using your own text corpus\n",
    "i=0\n",
    "list_of_sentance=[]\n",
    "for sentance in preprocessed_reviews:\n",
    "    list_of_sentance.append(sentance.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GIbKBSkRCAac",
    "outputId": "d72c6206-2c3f-4143-8c21-3f5b674310df",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using Google News Word2Vectors\n",
    "\n",
    "# in this project we are using a pretrained model by google\n",
    "# its 3.3G file, once you load this into your memory \n",
    "# it occupies ~9Gb, so please do this step only if you have >12G of ram\n",
    "# we will provide a pickle file wich contains a dict , \n",
    "# and it contains all our courpus words as keys and  model[word] as values\n",
    "# To use this code-snippet, download \"GoogleNews-vectors-negative300.bin\" \n",
    "# from https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit\n",
    "# it's 1.9GB in size.\n",
    "\n",
    "\n",
    "# http://kavita-ganesan.com/gensim-word2vec-tutorial-starter-code/#.W17SRFAzZPY\n",
    "# you can comment this whole cell\n",
    "# or change these varible according to your need\n",
    "\n",
    "is_your_ram_gt_16g=False\n",
    "want_to_use_google_w2v = False\n",
    "want_to_train_w2v = True\n",
    "\n",
    "if want_to_train_w2v:\n",
    "    # min_count = 5 considers only words that occured atleast 5 times\n",
    "    w2v_model=Word2Vec(list_of_sentance,min_count=5,size=50, workers=4)\n",
    "    print(w2v_model.wv.most_similar('great'))\n",
    "    print('='*50)\n",
    "    print(w2v_model.wv.most_similar('worst'))\n",
    "    \n",
    "elif want_to_use_google_w2v and is_your_ram_gt_16g:\n",
    "    if os.path.isfile('GoogleNews-vectors-negative300.bin'):\n",
    "        w2v_model=KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "        print(w2v_model.wv.most_similar('great'))\n",
    "        print(w2v_model.wv.most_similar('worst'))\n",
    "    else:\n",
    "        print(\"you don't have gogole's word2vec file, keep want_to_train_w2v = True, to train your own w2v \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JEJGArtUCAae",
    "outputId": "943e0fc6-83f8-455b-ba53-8dd05428fc92"
   },
   "outputs": [],
   "source": [
    "w2v_words = list(w2v_model.wv.vocab)\n",
    "print(\"number of words that occured minimum 5 times \",len(w2v_words))\n",
    "print(\"sample words \", w2v_words[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EPjGCg7UCAag"
   },
   "source": [
    "## [4.4.1] Converting text into vectors using wAvg W2V, TFIDF-W2V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oPxfYXhMCAag"
   },
   "source": [
    "#### [4.4.1.1] Avg W2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sB4Y18rQCAag",
    "outputId": "c9f64dac-cc89-43e3-9820-fbc18c39a69e"
   },
   "outputs": [],
   "source": [
    "# average Word2Vec\n",
    "# compute average word2vec for each review.\n",
    "sent_vectors = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for sent in tqdm(list_of_sentance): # for each review/sentence\n",
    "    sent_vec = np.zeros(50) # as word vectors are of zero length 50, you might need to change this to 300 if you use google's w2v\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        if word in w2v_words:\n",
    "            vec = w2v_model.wv[word]\n",
    "            sent_vec += vec\n",
    "            cnt_words += 1\n",
    "    if cnt_words != 0:\n",
    "        sent_vec /= cnt_words\n",
    "    sent_vectors.append(sent_vec)\n",
    "print(len(sent_vectors))\n",
    "print(len(sent_vectors[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sKAEsZZLCAam"
   },
   "source": [
    "#### [4.4.1.2] TFIDF weighted W2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pAVTG3brCAao"
   },
   "outputs": [],
   "source": [
    "# S = [\"abc def pqr\", \"def def def abc\", \"pqr pqr def\"]\n",
    "model = TfidfVectorizer()\n",
    "model.fit(preprocessed_reviews)\n",
    "# we are converting a dictionary with word as a key, and the idf as a value\n",
    "dictionary = dict(zip(model.get_feature_names(), list(model.idf_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tyxhz3XQCAap",
    "outputId": "e72f3ca0-7d29-4657-a107-c5d678514cf3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TF-IDF weighted Word2Vec\n",
    "tfidf_feat = model.get_feature_names() # tfidf words/col-names\n",
    "# final_tf_idf is the sparse matrix with row= sentence, col=word and cell_val = tfidf\n",
    "\n",
    "tfidf_sent_vectors = []; # the tfidf-w2v for each sentence/review is stored in this list\n",
    "row=0;\n",
    "for sent in tqdm(list_of_sentance): # for each review/sentence \n",
    "    sent_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    weight_sum =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        if word in w2v_words and word in tfidf_feat:\n",
    "            vec = w2v_model.wv[word]\n",
    "#             tf_idf = tf_idf_matrix[row, tfidf_feat.index(word)]\n",
    "            # to reduce the computation we are \n",
    "            # dictionary[word] = idf value of word in whole courpus\n",
    "            # sent.count(word) = tf valeus of word in this review\n",
    "            tf_idf = dictionary[word]*(sent.count(word)/len(sent))\n",
    "            sent_vec += (vec * tf_idf)\n",
    "            weight_sum += tf_idf\n",
    "    if weight_sum != 0:\n",
    "        sent_vec /= weight_sum\n",
    "    tfidf_sent_vectors.append(sent_vec)\n",
    "    row += 1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Amazon Fine Food Reviews Analysis.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
